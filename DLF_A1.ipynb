{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_sparse_dataset(file_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            label = int(parts[0])  # The first element is the label (+1 or -1)\n",
    "            features = np.zeros(8)  # Since we have 8 features in this dataset\n",
    "            \n",
    "            # Extract each feature's value\n",
    "            for part in parts[1:]:\n",
    "                index, value = part.split(':')\n",
    "                features[int(index) - 1] = float(value)\n",
    "            \n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '/Users/chayonimeu/Documents/GitHub/DLF_Perceptron-to-predict-diabetes/diabetes_scale.txt'\n",
    "X, y = load_sparse_dataset(data_path)\n",
    "\n",
    "# Convert labels from {-1, 1} to {0, 1} if needed, as many algorithms expect binary labels in {0, 1}\n",
    "y = np.where(y == -1, 0, 1)\n",
    "\n",
    "print(\"Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Single-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Initialize the Perceptron model\n",
    "perceptron_model = Perceptron(max_iter=1000, eta0=1.0, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "perceptron_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7272727272727273\n",
      "Confusion Matrix:\n",
      "[[17 38]\n",
      " [ 4 95]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.31      0.45        55\n",
      "           1       0.71      0.96      0.82        99\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.76      0.63      0.63       154\n",
      "weighted avg       0.75      0.73      0.69       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = perceptron_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display the classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SMOTE to Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after SMOTE: 0.7662337662337663\n",
      "Confusion Matrix after SMOTE:\n",
      "[[39 16]\n",
      " [20 79]]\n",
      "Classification Report after SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        55\n",
      "           1       0.83      0.80      0.81        99\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.75      0.75       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize and train the perceptron model on resampled data\n",
    "perceptron_model_smote = Perceptron(max_iter=1000, eta0=1.0, random_state=42)\n",
    "perceptron_model_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_smote = perceptron_model_smote.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "conf_matrix_smote = confusion_matrix(y_test, y_pred_smote)\n",
    "class_report_smote = classification_report(y_test, y_pred_smote)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy after SMOTE: {accuracy_smote}\")\n",
    "print(\"Confusion Matrix after SMOTE:\")\n",
    "print(conf_matrix_smote)\n",
    "print(\"Classification Report after SMOTE:\")\n",
    "print(class_report_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Class Weights to Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Class Weights: 0.7077922077922078\n",
      "Confusion Matrix with Class Weights:\n",
      "[[27 28]\n",
      " [17 82]]\n",
      "Classification Report with Class Weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.55        55\n",
      "           1       0.75      0.83      0.78        99\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.66      0.67       154\n",
      "weighted avg       0.70      0.71      0.70       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the perceptron model with class weights\n",
    "perceptron_model_weighted = Perceptron(max_iter=1000, eta0=1.0, random_state=42, class_weight='balanced')\n",
    "perceptron_model_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_weighted = perceptron_model_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "conf_matrix_weighted = confusion_matrix(y_test, y_pred_weighted)\n",
    "class_report_weighted = classification_report(y_test, y_pred_weighted)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy with Class Weights: {accuracy_weighted}\")\n",
    "print(\"Confusion Matrix with Class Weights:\")\n",
    "print(conf_matrix_weighted)\n",
    "print(\"Classification Report with Class Weights:\")\n",
    "print(class_report_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'eta0': 0.1, 'max_iter': 500}\n",
      "Accuracy after Hyperparameter Tuning: 0.7402597402597403\n",
      "Confusion Matrix after Tuning:\n",
      "[[18 37]\n",
      " [ 3 96]]\n",
      "Classification Report after Tuning:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.33      0.47        55\n",
      "           1       0.72      0.97      0.83        99\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.79      0.65      0.65       154\n",
      "weighted avg       0.77      0.74      0.70       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'eta0': [0.1, 0.5, 1.0, 5.0],  # Different learning rates\n",
    "    'max_iter': [500, 1000, 2000]   # Different iterations\n",
    "}\n",
    "\n",
    "# Initialize Perceptron with grid search\n",
    "perceptron_model_tuned = Perceptron(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(perceptron_model_tuned, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Accuracy after Hyperparameter Tuning: {accuracy_best}\")\n",
    "print(\"Confusion Matrix after Tuning:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report after Tuning:\")\n",
    "print(class_report_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.66666667 0.77235772 0.67479675 0.73170732 0.40983607]\n",
      "Average Cross-Validation Score: 0.6510729041716647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(perceptron_model_smote, X_train, y_train, cv=5)\n",
    "\n",
    "# Display cross-validation results\n",
    "print(f\"Cross-Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Average Cross-Validation Score: {cross_val_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (first 5):\n",
      " [[-0.294118    0.487437    0.180328   -0.292929   -1.          0.00149028\n",
      "  -0.53117    -0.0333333 ]\n",
      " [-0.882353   -0.145729    0.0819672  -0.414141   -1.         -0.207153\n",
      "  -0.766866   -0.666667  ]\n",
      " [-0.0588235   0.839196    0.0491803  -1.         -1.         -0.305514\n",
      "  -0.492741   -0.633333  ]\n",
      " [-0.882353   -0.105528    0.0819672  -0.535354   -0.777778   -0.162444\n",
      "  -0.923997   -1.        ]\n",
      " [-1.          0.376884   -0.344262   -0.292929   -0.602837    0.28465\n",
      "   0.887276   -0.6       ]]\n",
      "Labels (first 5):\n",
      " [-1.  1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "data_path = '/Users/chayonimeu/Documents/GitHub/DLF_Perceptron-to-predict-diabetes/diabetes_scale.txt'\n",
    "\n",
    "# Load the dataset (X: features, y: labels)\n",
    "X, y = load_svmlight_file(data_path)\n",
    "\n",
    "# Convert to dense format\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Display the first 5 examples (features and labels)\n",
    "print(\"Features (first 5):\\n\", X_dense[:5])\n",
    "print(\"Labels (first 5):\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "Label    0\n",
      "dtype: int64\n",
      "\n",
      "Data types of the features:\n",
      " 0        float64\n",
      "1        float64\n",
      "2        float64\n",
      "3        float64\n",
      "4        float64\n",
      "5        float64\n",
      "6        float64\n",
      "7        float64\n",
      "Label    float64\n",
      "dtype: object\n",
      "\n",
      "Feature value ranges (min, max):\n",
      "        0    1    2    3    4    5    6    7\n",
      "min -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0\n",
      "max  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "\n",
      "Class distribution:\n",
      " Label\n",
      " 1.0    500\n",
      "-1.0    268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert X_dense and y into a Pandas DataFrame for easier analysis\n",
    "df_features = pd.DataFrame(X_dense)\n",
    "df_labels = pd.DataFrame(y, columns=['Label'])\n",
    "\n",
    "# Concatenate features and labels for easy reference\n",
    "df = pd.concat([df_features, df_labels], axis=1)\n",
    "\n",
    "# 1. Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# 2. Check data types\n",
    "print(\"\\nData types of the features:\\n\", df.dtypes)\n",
    "\n",
    "# 3. Ensure feature scaling (checking min and max values)\n",
    "print(\"\\nFeature value ranges (min, max):\\n\", df_features.describe().loc[['min', 'max']])\n",
    "\n",
    "# 4. Check for class imbalance\n",
    "class_counts = df_labels['Label'].value_counts()\n",
    "print(\"\\nClass distribution:\\n\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6948051948051948\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dense, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Perceptron model with class weights to balance the classes\n",
    "perceptron = Perceptron(class_weight='balanced')\n",
    "\n",
    "# Train the model\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(eta0=0.01, max_iter=1000, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.74675325 0.74025974 0.62987013 0.75816993 0.34640523]\n",
      "Average cross-validation score: 0.644291656056362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(perceptron, X_dense, y, cv=5)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Average cross-validation score:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7077922077922078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "logistic_reg = LogisticRegression(class_weight='balanced')\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "y_pred_log = logistic_reg.predict(X_test)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[41 14]\n",
      " [33 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "Confusion Matrix:\n",
      " [[55 46]\n",
      " [14 85]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.80      0.54      0.65       101\n",
      "         1.0       0.65      0.86      0.74        99\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.72      0.70      0.69       200\n",
      "weighted avg       0.72      0.70      0.69       200\n",
      "\n",
      "Cross-validation scores: [0.585 0.685 0.52  0.62  0.57 ]\n",
      "Average cross-validation score: 0.596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your X_dense and y are already loaded from the dataset\n",
    "\n",
    "# Step 1: Handle Class Imbalance with SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_dense, y)\n",
    "\n",
    "# Step 2: Split the Dataset into Training and Test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Initialize and Train the Perceptron Model\n",
    "perceptron = Perceptron(class_weight='balanced', max_iter=1000, eta0=0.01)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification Report (Precision, Recall, F1-score)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# Cross-Validation (5-fold CV) on the resampled dataset\n",
    "cv_scores = cross_val_score(perceptron, X_resampled, y_resampled, cv=5)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Average cross-validation score:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
